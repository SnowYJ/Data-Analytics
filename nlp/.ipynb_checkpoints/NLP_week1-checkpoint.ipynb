{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.词向量：\n",
    "\n",
    "**将单词用向量表示。**\n",
    "\n",
    "### 1.1 one-hot encoding:\n",
    "\n",
    "将单词由向量表示，向量长度为词典内单词的数量。\n",
    "<img src=\"NLP_github/one_hot.png\" width=\"400\" height=\"300\">\n",
    "\n",
    "### 总结：\n",
    "\n",
    "1. one-hot 编码属于词袋模型（bag-of-words），因此，单词之间的关系前后顺序被忽略。\n",
    "\n",
    "2. one-hot 编码对**离散或分类的特征值**有效。\n",
    "\n",
    "3. one-hot 编码让特征之间的**距离计算**更加合理，距离的计算在分类算法中尤为重要。\n",
    "\n",
    "4. one-hot 编码在一定程度上起到了**扩充特征**的作用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
      "[[1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1.]]\n",
      "[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
      "[[0. 0. 0.]\n",
      " [1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
    "\n",
    "enc.fit(X)\n",
    "print(enc.categories_)\n",
    "\n",
    "print(enc.transform([['Female', 1], ['Male', 3]]).toarray())\n",
    "\n",
    "enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])\n",
    "\n",
    "enc.get_feature_names(['gender', 'group'])\n",
    "\n",
    "drop_enc = OneHotEncoder(drop='first').fit(X) # drop ??\n",
    "\n",
    "print(drop_enc.categories_)\n",
    "\n",
    "print(drop_enc.transform([['Female', 1], ['Male', 3]]).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 document-word matrix:\n",
    "\n",
    "**假设经常出现在同一类型文章中词是有关联的，例如：bank与cash。**\n",
    "<img src=\"NLP_github/d_w.png\" width=\"500\" height=\"400\">\n",
    "\n",
    "### 总结：\n",
    "矩阵尺寸会随着文章数量的增多而缩放。\n",
    "\n",
    "**document vector：(bag-of-words) 用于计算文本间的相似度，因此，可以用来进行文本分类。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 word-word matrix（Window based Co-occurrence Matrix）:\n",
    "\n",
    "行为目标单词，列为内容单词。其中的值为目标单词与内容单词在**某一窗口**内共同出现的次数，此数值是基于所有文本（document-word matrix内的值为某一文本中单词出现的频率）。**通常情况，目标单词等于内容单词。**\n",
    "\n",
    "<img src=\"NLP_github/w_w.png\" width=\"500\" height=\"400\">\n",
    "\n",
    "**可对上述参数进一步修改，根据距离进行赋值。**\n",
    "\n",
    "<img src=\"NLP_github/window_based.png\" width=\"500\" height=\"400\">\n",
    "\n",
    "**word vector: (word-embedding)单词之间的相似度。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metrices:\n",
    "\n",
    "**对于上述矩阵(w-d, w-w)中的参数可以根据不同的策略进行赋值。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 PMI:\n",
    "\n",
    "**衡量两随机变量之间的相关性。**\n",
    "\n",
    "$$\n",
    "\\text{PMI}(w_i, w_j) =\\log_2 \\frac{\\text{P}(w_i, w_j)}{\\text{P}(w_i)P(w_j)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{PPMI}(w_i, w_j) = \\max(PMI, 0)\n",
    "$$\n",
    "\n",
    "如果两变量之间相互独立，PMI为0。如果两变量之间不是相互独立，则$\\text{P}(w_i, w_j)>\\text{P}(w_i)P(w_j)$，PMI越大说明两变量携带共同信息多，越有可能共同出现。\n",
    "\n",
    "### 2.2 TF.IDF:\n",
    "\n",
    "$$\n",
    "x_{word} = \\text{tf}_{word} \\log_{10} \\frac{\\text{N}}{\\text{df}_{word}}\n",
    "$$\n",
    "\n",
    "* N: 语料库中文本数量。\n",
    "\n",
    "* tf: term frequency或raw frequency。\n",
    "\n",
    "* df: document frequency。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 降维："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 对word-word矩阵进行奇异值分解：\n",
    "\n",
    "<img src=\"NLP_github/svd_word_matrix.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "### 3.2 LSA：对document-word矩阵进行奇异值分解\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
