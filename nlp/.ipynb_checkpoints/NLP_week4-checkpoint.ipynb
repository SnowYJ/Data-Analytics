{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 序列标注：\n",
    "\n",
    "## 1. 应用:\n",
    "\n",
    "<img src=\"NLP_github/sequence_labelling.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 隐马尔可夫模型 HMM - 有向图\n",
    "\n",
    "### 背景介绍：图模型 HMM & CRF\n",
    "\n",
    "<img src=\"NLP_github/graph_model.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "隐马尔可夫模型属于**概率生成模型**，通过对朴素贝叶斯或高斯混合模型增加序列可得到隐马尔可夫模型。\n",
    "\n",
    "概率生成模型：求联合概率。判别模型：求条件概率。\n",
    "\n",
    "### 2.1 隐马尔可夫模型：\n",
    "\n",
    "<img src=\"NLP_github/HMM.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "* 状态序列：$I = i_1, i_2, \\dots, i_t $. $\\text{Q} = {q_1, q_2, \\dots, q_n}$ 状态序列为隐变量。\n",
    "\n",
    "* 观测序列：$O = o_1, o_2, \\dots, o_t $. $\\text{V} = {v_1, v_2, \\dots, v_m}$，观测序列为观测的结果。\n",
    "\n",
    "* 模型使用 $\\lambda = (\\pi, A, B)$ 表示。其中，$\\pi$为出始概率分布，A为状态转移矩阵，B为发射矩阵。\n",
    "\n",
    "* A 状态转移矩阵：$A[a_{ij}] = P(i_{t+1}|i_t)$。状态序列，i+1时刻下的概率仅与i时刻有关。**马尔可夫假设**\n",
    "\n",
    "* B 发射矩阵：$B[b_{jk}] = P(o_k|i_j)$。观测序列$o_k$对应的概率仅与其对应的状态有关。**观测独立假设**\n",
    "\n",
    "### 2.2 隐马尔可夫三个基本问题：\n",
    "\n",
    "1. 概率问题：给定模型计算观测序列出现的概率 $\\text{P}(\\text{O}|\\lambda)$。\n",
    "2. 机器学习问题：已知观测序列求解模型参数。\n",
    "3. Decoding问题：给定观测序列，求解最优的状态序列 $argmax P(I|O, \\lambda)$，例如：词性标注。\n",
    "\n",
    "<img src=\"NLP_github/HMM_1.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "### 2.2.1 问题一：给定$\\lambda$求$\\text{P}(\\text{O}|\\lambda)$\n",
    "\n",
    "**方法1:**\n",
    "\n",
    "$$\n",
    "\\text{P}(\\text{O}|\\lambda) = \\sum_\\text{I} \\text{P}(\\text{I}, \\text{O}|\\lambda) = \\sum_\\text{I} \\text{P}(\\text{O}|\\text{I}, \\lambda) \\text{P}(\\text{I}|\\lambda)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{P}(\\text{I}|\\lambda) = \\text{P}(i_t, i_{t-1}, \\dots, i, \\lambda) = \\text{P}(i_t|i_{t-1}, \\dots, i, \\lambda) \\text{P}(i_{t-1}, \\dots, i, \\lambda)\n",
    "$$\n",
    "根据马尔可夫假设：\n",
    "$$\n",
    "\\text{P}(i_t|i_{t-1}, \\dots, i, \\lambda) = \\text{P}(i_t|i_{t-1}, \\lambda) = a_{t, t-1}\n",
    "$$\n",
    "如上述步骤，最终概率如下：\n",
    "$$\n",
    "\\text{P}(\\text{I}|\\lambda) = \\pi (a_{1, 0}) \\prod_{t=2}^T a_{t+1, t}\n",
    "$$\n",
    "同理：\n",
    "$$\n",
    "\\text{P}(\\text{O}|\\text{I}, \\lambda) = \\prod_{t=1}^T b_{i, t} (o_t)\n",
    "$$\n",
    "$$\n",
    "\\text{P}(\\text{O}|\\lambda) = \\sum_\\text{I} \\pi (a_{1, 0}) \\prod_{t=2}^T a_{t+1, t} \\prod_{t=1}^T b_{i, t} (o_t) \n",
    "$$\n",
    "\n",
    "由于此方法时间复杂度为$O(n^T)$，n为状态序列为离散值的数量，因此不适用于特别长的序列。\n",
    "\n",
    "**方法2：**\n",
    "\n",
    "forward, backward\n",
    "https://www.bilibili.com/video/av32471608?p=3\n",
    "### 2.2.2 问题二：已知观测序列求解模型参数\n",
    "\n",
    "### 2.2.3 问题三：$argmax P(I|O, \\lambda)$\n",
    "\n",
    "**viterbi 维特比算法：选择有向无环图的最短路径。**\n",
    "\n",
    "https://www.zhihu.com/question/20136144\n",
    "\n",
    "例如下图选择从S到E的最短路径。\n",
    "\n",
    "<img src=\"NLP_github/viterbi_example.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "首先，选择出S到B列的最短路径，如下图所示。\n",
    "<img src=\"NLP_github/example_1.png\" width=\"400\" height=\"400\">\n",
    "同理，根据已知的三条最短路径，选择S到C的最短路径，如下图所示。\n",
    "<img src=\"NLP_github/example_2.png\" width=\"400\" height=\"400\">\n",
    "最终，对比选择出最短路径，如下图所示。\n",
    "<img src=\"NLP_github/example_3.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "例如：命名实体标注。\n",
    "\n",
    "<img src=\"NLP_github/NE.png\" width=\"700\" height=\"700\">\n",
    "\n",
    "横轴为状态序列，纵轴为观测序列。\n",
    "\n",
    "* s[i, j] 得分情况，其中i为观测序列的下标，j为状态序列的下标。\n",
    "\n",
    "* e[i, j] 为发射矩阵的元素。\n",
    "\n",
    "* t[i, j] 为状态转移矩阵的元素。\n",
    "\n",
    "记录选择状态节点的情况，使得score最大。\n",
    "\n",
    "https://msd.misuland.com/pd/2884250171976188572"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 条件随机场 CRF - 无向图\n",
    "\n",
    "**条件随机场属于概率判别模型，解决MeMM label bias问题。**\n",
    "\n",
    "条件随机场首先要定义一个特征函数集，每个特征函数都以整个句子s，当前位置i，位置i和i-1的标签为输入。然后为每一个特征函数赋予一个权重，然后针对每一个标注序列l，对所有的特征函数加权求和，必要的话，可以把求和的值转化为一个概率值。\n",
    "\n",
    "* 特征函数：$f(s, i, l_i, l_{i-1})$ s为需要被标注的句子，i为句子中第i个词，$l_i$为第i个单词的标注，$l_{i-1}$为第i-1个单词的标注。其输出为0或1，0代表此标注不符合此特征，反之，1代表符合此特征。\n",
    "\n",
    "\n",
    "* 特征函数集：多个特征对应的特征函数的集合。\n",
    "\n",
    "\n",
    "* 权重$\\lambda$：每一个特征函数$f_i$前有一个权重$\\lambda_i$权重的大小对应此特征正确或错误的程度。例如，有一特征函数表示名词前接形容词，因此我们希望此特征函数对应的权重为正值且越大越好。相反，某一特征函数表示动词前接形容词，我们希望此权重越小越好（可以为负数）。\n",
    "\n",
    "\n",
    "* $score(l|s) = \\sum_{j=1}^m \\sum_{i=1}^n \\lambda_j f_j(s, i, l_i, l_{i-1})$ i代表句子s中的每个单词，j代表特征函数集合内的每一个特征函数。\n",
    "\n",
    "将上述$score(l|s)$函数转换为概率表示为：\n",
    "\n",
    "$$\n",
    "P(l|s) = \\frac{exp\\left(score(l|s)\\right)}{\\sum_{l'} exp\\left(score(l'|s)\\right)}\n",
    "$$\n",
    "\n",
    "可以使用随机梯度下降更新换代权重：\n",
    "\n",
    "<img src=\"NLP_github/CRF_train.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "http://www.luyixian.cn/news_show_37209.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. HMM & CRF & LR & NB:\n",
    "\n",
    "<img src=\"NLP_github/CRF.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "逻辑回归是用于分类的对数线性模型，条件随机场是用于序列话标注的对数线性模型。\n",
    "\n",
    "朴素贝叶斯模型和隐马尔可夫模型需要建模的是输入变量和输出变量的**联合概率分布。**\n",
    "\n",
    "逻辑回归模型和条件随机场模型需要建模的是输入变量和输出变量的**条件概率分布。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
