{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语言模型:\n",
    "\n",
    "## 1. 应用：\n",
    "\n",
    "**1. 语种检测**\n",
    "**2. 信息检索**\n",
    "**3. 语法错误检测**\n",
    "**4. 语音识别**\n",
    "\n",
    "## 2. n-gram 语言模型：\n",
    "\n",
    "### 2.1 条件概率链式法则：\n",
    "\n",
    "首先，假设一个句子中每个单词相互独立，得到此句子的概率为：\n",
    "\n",
    "$$\n",
    "\\text{P}(X) = \\text{P}(x_1) \\text{P}(x_2) \\dots \\text{P}(x_{n-1})\\text{P}(x_n)\n",
    "$$\n",
    "\n",
    "然后， 句子中每个单词出现的概率与其前面的单词有关联，因此。得到的概率为：\n",
    "$$\n",
    "\\text{P}(X)= \\text{P}(x_1)\\text{P}(x_2|x_1)\\text{P}(x_3|x_2, x_1) \\dots \\text{P}(x_n|x_{n-1}, \\dots, x_1) = \\prod_{n=1}^N \\text{P}(x_n|x_1, \\dots, x_{n-1})\n",
    "$$\n",
    "\n",
    "**注意：由于一个句子包含多个单词，导致每个句子的概率过小。使用马尔可夫假设解决此问题。**\n",
    "\n",
    "### 2.2 马尔可夫假设：\n",
    "\n",
    "句子中每个单词出现的概率与前n个单词有关。概率公式如下：\n",
    "\n",
    "$$\n",
    "\\text{P}(x_n|x_{n-1}, \\dots, x_1) \\approx \\text{P}(x_n|x_n, \\dots, x_{n-k})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 困惑度 Perplexity：\n",
    "\n",
    "**用于评估语言模型好坏，语言模型越好，概率越高，困惑度越小。注意：只能用于评估概率语言模型。**\n",
    "\n",
    "$$\n",
    "PP(X) = \\sqrt[n]{\\frac{1}{\\text{P}(x_1, \\dots, x_n)}} = \\sqrt[n]{\\frac{1}{\\prod_{n=1}^N \\text{P}(x_n|x_1, \\dots, x_{n-1})}}\n",
    "$$\n",
    "\n",
    "## 4. Smoothing:\n",
    "\n",
    "### 4.1 拉普拉斯平滑 Add-1 smoothing:\n",
    "\n",
    "$$\n",
    "\\text{P}(x_n|x_{n-1}) = \\frac{counts(x_{n-1}, x_n) + 1}{counts(x_{n-1})+|\\text{V}|}\n",
    "$$\n",
    "\n",
    "### 4.2 Add-k smoothing:\n",
    "\n",
    "$$\n",
    "\\text{P}(x_n|x_{n-1}) = \\frac{counts(x_{n-1}, x_n) + k}{counts(x_{n-1})+k|\\text{V}|}\n",
    "$$\n",
    "\n",
    "**注意：k为超参数。**\n",
    "\n",
    "### 4.3 回退 Backoff：\n",
    "\n",
    "例如：\"chinese fried rice.\" 假设ngram为3。如果，训练集中均未出现\"chinese fired rice.\"**退而求其次**，查找\"chinese fried\"或\"fired rice.\"出现的概率。此方法称之为回退。\n",
    "\n",
    "$$\n",
    "\\text{BO}(x_n|x_{n-1}, \\dots, x_k) = \n",
    "\\begin{cases} \n",
    "\\text{P}(x_n|x_{n-1}, \\dots, x_{n-k}), \\text{if} c(x_n, \\dots, x_{n-k})>0 \\\\\n",
    "\\text{BO}(x_{n-1}|x_{n-2}, \\dots, x_{n-k+1}) \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{P}_\\text{BO}(x_n|x_{n-1}, \\dots, x_k) = \n",
    "\\begin{cases} \n",
    "\\text{P}^*(x_n|x_{n-1}, \\dots, x_{n-k}), \\text{if} c(x_n, \\dots, x_{n-k})>0 \\\\\n",
    "\\alpha^{x_{n-1}, \\dots, x_{n-k}}\\text{P}_\\text{BO}(x_{n-1}|x_{n-2}, \\dots, x_{n-k+1}) \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\alpha^{x_{n-1}, \\dots, x_{n-k}} = \\frac{\\beta^{x_{n-1}, \\dots, x_{n-k}}}{\\sum \\text{P}_\\text{BO}(x_{n-1}|x_{n-2}, \\dots, x_{n-k+1})}\n",
    "$$\n",
    "\n",
    "**Stupid Backoff:**\n",
    "<img src=\"NLP_github/stupid.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "### 4.4 插值 SLI： \n",
    "\n",
    "$$\n",
    "\\text{P}_{SLI} = \\lambda_1 \\text{P}(x_n|x_{n-1}, x_{n-2}) + \\lambda_2 \\text{P}(x_n|x_{n-1}) + \\lambda_3 \\text{P}(x_n), \\lambda_i > 0 \\sum \\lambda_i = 1\n",
    "$$\n",
    "\n",
    "### 4.5 Absolute Discounting:\n",
    "\n",
    "<img src=\"NLP_github/absolute_discounting.png\" width=\"200\" height=\"200\">\n",
    "\n",
    "$$\n",
    "\\text{P}_\\text{absDiscount}(x_n|x_{n-1}) = \\frac{c(x_n, x_{n-1})-d}{c(x_n-1)} + \\lambda (x_{n-1}) \\text{P}(x_n)\n",
    "$$\n",
    "\n",
    "**其中，d为0.75。**\n",
    "\n",
    "**Kneser-Ney Smoothing:**\n",
    "\n",
    "一个词出现的频率与其之前的词有关，例如：San Francisco。Francisco的高频率是与San有关的。因此，得到一个unigram语言模型，它对单词概率的计算需要考虑之前的单词。例如：San Francisco。虽然Francisco出现的次数很多，但是得到的概率却比较低，这是预期的效果。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
