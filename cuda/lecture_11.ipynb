{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Performance：\n",
    "\n",
    "**内存读取 Memory Access，SMP占有率 occupancy (cudaOccupancyMaxPotentialBlockSize)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  GPU内存使用策略 - Global Memory Coalescing：\n",
    "\n",
    "GPU从全局内存读取到L2，L1过程中尽量用Coalesing accessing的策略来最大化带宽bandwidth。所谓的 coalesced，采取了**连续的内存存取模式，而且它开始的地址，必须是每个 thread 所存取的大小的 16 倍**。例如，如果每个thread 都读取 32 bits 的数据，那么第一个 thread 读取的地址，必须是 16 * 4 = 64 bytes 的倍数。\n",
    "\n",
    "<img src=\"image_github/CGM.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 缓存行 cache line：\n",
    "\n",
    "全局内存的数据首先通过L2缓存，至于是否通过L1缓存因情况而定。\n",
    "\n",
    "<img src=\"image_github/cache_line.png\" width=\"700\" height=\"500\">\n",
    "\n",
    "### 2.1 L2与L1缓存：\n",
    "\n",
    "* **L2 L1 Coalesced Memory Access: 正常情况**\n",
    "<img src=\"image_github/L2.png\" width=\"700\" height=\"400\">\n",
    "\n",
    "* **L2 L1 Permuted Memory Access: 在128比特以内的重新排列不会导致多次加载**\n",
    "<img src=\"image_github/L2_1.png\" width=\"700\" height=\"400\">\n",
    "<img src=\"image_github/L2_2.png\" width=\"700\" height=\"400\">\n",
    "\n",
    "* **L2 Offset Memory Access: 利用率会下降，因为需要传递5次**\n",
    "<img src=\"image_github/L2_offset.png\" width=\"700\" height=\"400\">\n",
    "\n",
    "* **L1 Offset Memory Access: 利用率会下降50%！！！**\n",
    "<img src=\"image_github/L1_offset.png\" width=\"700\" height=\"400\">\n",
    "\n",
    "* **L2 Strided Memory Access：步幅为2（如下图），利用率为50%，需要8次传递**\n",
    "<img src=\"image_github/L2_stride.png\" width=\"700\" height=\"400\">\n",
    "<img src=\"image_github/L2_stride_performance.png\" width=\"500\" height=\"400\">\n",
    "\n",
    "### 2.2 总结：\n",
    "\n",
    "* L1需要避免 Offset Memory Access，以及L2需要避免 Strided Memory Access。\n",
    "* L2和L1的 Coalesced 或 Permuted Memory Access 不会导致性能下降，注意在边界内（128B）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Array of Structures vs Structures of Arrays:\n",
    "\n",
    "* **Array of Structures: (AoS)**\n",
    "<img src=\"image_github/AoS.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "* **Structures of Arrays: (SoA)**\n",
    "<img src=\"image_github/SoA.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  SMP的占有率：\n",
    "\n",
    "### 4.1 占有率与线程块：\n",
    "<img src=\"image_github/occupancy.png\" width=\"600\" height=\"500\">\n",
    "\n",
    "### 4.2 计算占有率：\n",
    "<img src=\"image_github/occupancy_calculator.png\" width=\"600\" height=\"500\">\n",
    "\n",
    "### 4.3 Occupancy API：\n",
    "**使用cudaOccupancyMaxPotentialBlockSize()函数。**\n",
    "<img src=\"image_github/intelligent.png\" width=\"600\" height=\"500\">\n",
    "<img src=\"image_github/intelligent_1.png\" width=\"600\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Wave & Tail:\n",
    "\n",
    "<img src=\"image_github/wave_tail.png\" width=\"600\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 总结：\n",
    "\n",
    "<img src=\"image_github/summary.png\" width=\"600\" height=\"500\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
