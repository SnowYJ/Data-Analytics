{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA 内存："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * local memory：局部内存\n",
    "* shared memory：共享内存\n",
    "* constant memory：常量内存\n",
    "* global memory：全局内存\n",
    "* unified memory：统一内存\n",
    "* read-only memory：只读内存\n",
    "* texture memory：纹理内存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 寄存器：\n",
    "\n",
    "寄存器是GPU中最快的内存，一般kernal中没有特殊声明的自动变量都存放在寄存器中。**寄存器是每个线程的私有变量，一旦线程执行结束，寄存器变量就会失效。如果kernal使用的寄存器超过硬件限制，这部分数据会存入局部内存中。**如下图所示：\n",
    "\n",
    "<img src=\"image_github/GPU_memory.png\" width=\"400\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.局部缓存：局部缓存与全局缓存在同一块存储区\n",
    "\n",
    "### 2.1 什么时候使用局部内存：\n",
    "\n",
    ">* 编译期间无法确定值的本地数组。\n",
    "* 消耗太多寄存器的较大结构体或数组。\n",
    "* 任何超过寄存器限制的变量。\n",
    "\n",
    "<img src=\"image_github/local_memory.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 共享缓存：\n",
    "\n",
    "共享缓存尽管在核函数中声明，但是其生命周期是伴随整个线程块，而不是单个线程。当该线程块执行完毕，所拥有的资源就会被释放，重新分配给别的线程块。共享缓存是同一个线程块中线程交流的基本方式。**获取共享缓存内的数据必须使用syncthreads()同步。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 常量内存：\n",
    "\n",
    "**常量内存是用来保存在核函数执行期间不会发生变化的数据。**\n",
    "\n",
    "### 4.1 常量缓存声明：\n",
    "\n",
    "<img src=\"image_github/half_warp.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "**注意：在确定常量内存长度时，不要使用宏定义。因为宏定义在预处理过程读入源代码。**\n",
    "\n",
    "### 4.2 CPU内存复制到GPU常量内存：\n",
    "\n",
    "**使用cudaMemcpyToSymbol()将CPU内存数据复制到GPU常量数据中**，其与参数为cudaMemcpyHostToDevice的cudaMemcpy()之间的唯一差异在于，cudaMemcpyToSymbol()会复制到常量内存，而cudaMemcpy()会复制到全局内存。\n",
    "\n",
    "### 4.3 常量缓存的优点：\n",
    "\n",
    "* 对常量内存的单次读操作可以广播到其他的“邻近(nearby)”线程，这将节约15次读取操作。\n",
    "\n",
    ">当处理常量内存时，NVIDIA硬件将把单次内存读取操作广播到每个半线程束(Half-Warp)。在半线程束中包含16个线程，即线程束中线程数量的一半。如果在半线程束中的每个线程从常量内存的相同地址上读取数据，那么GPU只会产生一次读取请求并在随后将数据广播到每个线程。如果从常量内存中读取大量数据，那么这种方式产生的内存流量只是使用全局内存时的1/16。**线程束(warp)：在CUDA架构中，线程束是指一个包含32个线程的集合，这个线程集合被“编织在一起”并且以“步调一致(Lockstep)”的形式执行。在程序中的每一行，线程束中的每个线程都将在不同的数据上执行相同的指令。**\n",
    "\n",
    "* 常量内存的数据将缓存起来，因此对于相同地址的连续操作将不会产生额外的内存通信量。\n",
    "\n",
    ">由于这块内存的内容是不发生变化的，因此硬件将主动把这个常量数据缓存在GPU上。在第一次从常量内存的某个地址上读取后，当其他半线程束请求同一个地址时，那么将**命中缓存**（缓存有需要的数据），这同样减少了额外的内存流量。\n",
    "\n",
    "**注意：虽然当所有16个线程都读取相同地址时，这个功能可以极大提升性能，但当所有16个线程分别读取不同的地址时，它实际上会降低性能。因为这16次不同的读取操作会被串行化，从而需要16倍的时间来发出请求。但如果从全局内存中读取，那么这些请求会同时发出。**\n",
    "\n",
    "https://blog.csdn.net/Linoi/java/article/details/41522573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 全局内存：\n",
    "\n",
    "### 6. 统一内存：\n",
    "\n",
    "不需要将数据从CPU内存复制到GPU内存。\n",
    "\n",
    "<img src=\"image_github/unified_memory_1.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "<img src=\"image_github/unified_memory.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 只读内存：\n",
    "\n",
    "> 1. 使用 const 与 restrict 关键字。\n",
    "> 2. 使用ldg。\n",
    "\n",
    "<img src=\"image_github/read_only_1.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "<img src=\"image_github/read_only.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 纹理内存：\n",
    "\n",
    "\n",
    "### 8.1 纹理内存介绍：\n",
    "\n",
    "**和常量内存一样，纹理内存是另一种类型的只读内存**，在特定的访问模式中，纹理内存同样能够提升性能并减少内存流量。**纹理缓存是专门为那些在内存访问模式中存在大量空间局部性(Spatial Locality)的图形应用程序而设计的**。在某个计算应用程序中，这意味着**一个线程读取的位置可能与邻近线程的读取位置“非常接近”**，如下图所示。\n",
    "\n",
    "<img src=\"image_github/texture.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "从数学的角度，上图中的4个地址并非连续的，在一般的CPU缓存中，这些地址将不会缓存。但由于GPU纹理缓存是专门为了加速这种访问模式而设计的，因此如果在这种情况中使用纹理内存而不是全局内存，那么将会获得性能的提升。\n",
    "\n",
    "### 8.2 代码：\n",
    "\n",
    "**声明一维：其中读取类型如下读取类型**\n",
    "> * cudaReadModeNormalizedFloat，将数据归一化处理。\n",
    "> * cudaReadModeElementType，默认是cudaReadModeElementType。\n",
    "\n",
    "**绑定与解绑：令某一块内存为纹理内存**\n",
    "> * cudaBindTexture\n",
    "> * cudaUnbindTexture\n",
    "\n",
    "<img src=\"image_github/texture_code.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "**声明二维：**\n",
    "\n",
    "<img src=\"image_github/texture_code_2D.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. CUDA 计时：\n",
    "\n",
    "<img src=\"image_github/time_record.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
